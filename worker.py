#!/usr/bin/env python3
"""
üîÑ Alpha Vantage Trading Framework - Background Worker
Arka planda s√ºrekli √ßalƒ±≈üarak veri g√ºncelleme sistemi
"""

import time
import os
import logging
from datetime import datetime

# Flask app ve modellerini import et
from web_app import app, db, User, Watchlist, CachedData, CorrelationCache, Asset, DailyBriefing
from alphavantage_provider import AlphaVantageProvider
from universal_trading_framework import UniversalTradingBot, AssetType

# Import configurations
from constants import CORRELATION_CONFIG, API_CONFIG

# Additional imports for correlation calculation
import pandas as pd
from sqlalchemy import text

# Loglama kurulumu
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def get_asset_type(symbol, available_assets):
    """Sembol i√ßin doƒüru asset type'ƒ± bul"""
    for asset_type, symbols in available_assets.items():
        if symbol in symbols:
            if asset_type == 'forex':
                return AssetType.FOREX
            elif asset_type == 'stocks':
                return AssetType.STOCKS
            elif asset_type == 'crypto':
                return AssetType.CRYPTO
    return AssetType.STOCKS  # Default

def calculate_smart_scores(analysis, symbol):
    """üß† Akƒ±llƒ± skorlama sistemi - Fƒ±rsatlarƒ±n kalitesini belirler"""
    try:
        # Temel deƒüerler
        signal = analysis.get('final_signal', 'hold')
        
        # 1. Confidence Score (0-100)
        confidence_score = 0.0
        if signal == 'buy':
            confidence_score = 75.0  # BUY i√ßin base skor
        elif signal == 'sell':
            confidence_score = 70.0  # SELL i√ßin base skor
        else:
            confidence_score = 30.0  # HOLD i√ßin d√º≈ü√ºk skor
        
        # 2. Technical Strength (0-100) - Sinyal g√ºc√º
        technical_strength = 50.0  # Base
        
        # Kƒ±sa ve uzun vadeli sinyaller aynƒ±ysa g√º√ßl√º
        if (analysis.get('technical_signal_short') == analysis.get('technical_signal_long') and 
            analysis.get('technical_signal_short') == signal):
            technical_strength += 25.0
        
        # Prediction ile uyumlu ise g√º√ßl√º
        if analysis.get('prediction_signal') == signal:
            technical_strength += 15.0
            
        # 3. Volume Score (0-100) - Hacim analizi
        volume_score = 60.0  # Varsayƒ±lan orta seviye
        
        # 4. Momentum Score (0-100) - Price momentum
        momentum_score = 55.0  # Base momentum
        current_price = analysis.get('current_price', 0)
        
        # Fiyat seviyesine g√∂re momentum ayarla
        if current_price > 0:
            if signal == 'buy' and current_price > 100:  # Y√ºksek fiyatlƒ± hisse
                momentum_score += 10.0
            elif signal == 'sell' and current_price < 50:  # D√º≈ü√ºk fiyatlƒ± hisse
                momentum_score += 15.0
        
        # 5. Risk Level belirleme
        risk_level = 'medium'  # Default
        
        # Crypto'lar y√ºksek risk
        from constants import AVAILABLE_ASSETS
        if symbol in AVAILABLE_ASSETS['crypto']:
            risk_level = 'high'
            confidence_score -= 5.0  # Crypto riski
        
        # Forex orta risk
        elif symbol in AVAILABLE_ASSETS['forex']:
            risk_level = 'medium'
        
        # Major stocks d√º≈ü√ºk risk
        elif symbol in ['AAPL', 'GOOGL', 'MSFT', 'AMZN', 'NVDA']:
            risk_level = 'low'
            confidence_score += 10.0  # Blue chip bonus
        
        # Skorlarƒ± 0-100 aralƒ±ƒüƒ±nda tut
        confidence_score = max(0, min(100, confidence_score))
        technical_strength = max(0, min(100, technical_strength))
        volume_score = max(0, min(100, volume_score))
        momentum_score = max(0, min(100, momentum_score))
        
        return {
            'confidence_score': confidence_score,
            'technical_strength': technical_strength,
            'volume_score': volume_score,
            'momentum_score': momentum_score,
            'risk_level': risk_level
        }
        
    except Exception as e:
        logger.warning(f"Smart score calculation error for {symbol}: {e}")
        return {
            'confidence_score': 50.0,
            'technical_strength': 50.0,
            'volume_score': 50.0,
            'momentum_score': 50.0,
            'risk_level': 'medium'
        }

def get_active_symbols_from_db():
    """Veritabanƒ±ndan aktif olan t√ºm varlƒ±k sembollerini √ßeker"""
    with app.app_context():
        try:
            # Asset tablosundan aktif varlƒ±klarƒ± √ßek (populate_assets.py ile tutarlƒ± naming)
            forex_assets = [a.symbol for a in Asset.query.filter_by(asset_type='forex', is_active=True).all()]
            stock_assets = [a.symbol for a in Asset.query.filter_by(asset_type='stock', is_active=True).all()]  # FIX: 'stock' not 'stocks'
            crypto_assets = [a.symbol for a in Asset.query.filter_by(asset_type='crypto', is_active=True).all()]
            
            logger.info(f"üìä Database'den √ßekilen varlƒ±klar:")
            logger.info(f"   Forex: {len(forex_assets)} varlƒ±k")
            logger.info(f"   Stocks: {len(stock_assets)} varlƒ±k")  
            logger.info(f"   Crypto: {len(crypto_assets)} varlƒ±k")
            
            # Eƒüer database bo≈üsa, fallback constants kullan
            total_assets = len(forex_assets) + len(stock_assets) + len(crypto_assets)
            
            if total_assets == 0:
                logger.warning("‚ö†Ô∏è Database'de varlƒ±k bulunamadƒ±, fallback constants kullanƒ±lƒ±yor")
                # Fallback to constants if database is empty
                from constants import AVAILABLE_ASSETS
                return AVAILABLE_ASSETS
            
            return {
                'forex': forex_assets,
                'stocks': stock_assets,  # Keep 'stocks' key for compatibility with other parts
                'crypto': crypto_assets
            }
        except Exception as e:
            logger.error(f"‚ùå Database varlƒ±k okuma hatasƒ±: {e}")
            logger.warning("‚ö†Ô∏è Fallback constants kullanƒ±lƒ±yor")
            # Fallback to constants on error
            from constants import AVAILABLE_ASSETS
            return AVAILABLE_ASSETS

def calculate_and_store_correlations(provider):
    """T√ºm varlƒ±klar i√ßin korelasyon matrisini hesaplar ve veritabanƒ±na kaydeder"""
    logger.info("üìà Dinamik korelasyon hesaplamasƒ± ba≈ülƒ±yor...")
    
    # T√ºm sembolleri database'den al
    available_assets = get_active_symbols_from_db()
    all_symbols = (available_assets['forex'] + 
                   available_assets['stocks'] + 
                   available_assets['crypto'])
    
    price_data = {}
    
    logger.info(f"üìä Tarihsel veri √ßekiliyor ({len(all_symbols)} varlƒ±k)...")
    
    for symbol in all_symbols:
        try:
            # 90 g√ºnl√ºk veri al (daha stabil korelasyon i√ßin)
            days_back = CORRELATION_CONFIG['historical_days']
            # 15dk periyotlarla g√ºnl√ºk data: 96 periyot/g√ºn * 90 g√ºn = 8640 periyot
            data_points = 96 * days_back
            
            df = provider.get_historical_data(symbol, 
                                            CORRELATION_CONFIG['timeframe'], 
                                            data_points)
            
            if not df.empty and len(df) >= CORRELATION_CONFIG['min_data_points']:
                # Close fiyatlarƒ± al
                price_data[symbol] = df['Close'].ffill(limit=10).dropna()
                logger.info(f"‚úÖ {symbol}: {len(price_data[symbol])} veri noktasƒ±")
            else:
                logger.warning(f"‚ö†Ô∏è {symbol}: Yetersiz veri ({len(df) if not df.empty else 0} nokta)")
            
            # Rate limiting
            time.sleep(1.5)
            
        except Exception as e:
            logger.warning(f"‚ùå {symbol} korelasyon verisi alƒ±namadƒ±: {e}")

    if len(price_data) < 10:
        logger.error("‚ùå Korelasyon i√ßin yeterli veri toplanamadƒ±.")
        return False

    try:
        # Y√ºzdesel deƒüi≈üime g√∂re korelasyon hesapla (daha stabil)
        full_df = pd.DataFrame(price_data).pct_change(fill_method=None).dropna()
        correlation_matrix = full_df.corr()
        
        logger.info("‚úÖ Korelasyon matrisi hesaplandƒ±. Veritabanƒ±na kaydediliyor...")
        
        # Flask app context i√ßinde database i≈ülemleri
        with app.app_context():
            # Veritabenƒ±na kaydet
            valid_correlations = 0
            
            # √ñnceki verileri temizle
            CorrelationCache.query.delete()
            
            # Yeni verileri ekle
            for symbol_1 in correlation_matrix.columns:
                for symbol_2 in correlation_matrix.columns:
                    if symbol_1 >= symbol_2:  # Tekrarlƒ± √ßiftleri √∂nle
                        continue
                    
                    corr_value = correlation_matrix.loc[symbol_1, symbol_2]
                    
                    # NaN olmayan ve anlamlƒ± korelasyonlarƒ± kaydet
                    if pd.notna(corr_value) and abs(corr_value) >= CORRELATION_CONFIG['correlation_threshold']:
                        new_corr = CorrelationCache(
                            symbol_1=symbol_1,
                            symbol_2=symbol_2,
                            correlation_value=float(corr_value)
                        )
                        db.session.add(new_corr)
                        valid_correlations += 1
            
            db.session.commit()
            logger.info(f"‚úÖ {valid_correlations} anlamlƒ± korelasyon veritabanƒ±na kaydedildi")
            
            # √ñrnek korelasyonlarƒ± logla
            sample_corrs = CorrelationCache.query.order_by(CorrelationCache.correlation_value.desc()).limit(5).all()
            for corr in sample_corrs:
                logger.info(f"üìä En y√ºksek korelasyon: {corr.symbol_1} ‚Üî {corr.symbol_2}: {corr.correlation_value:.3f}")
                
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Korelasyon hesaplama/kaydetme hatasƒ±: {e}")
        with app.app_context():
            db.session.rollback()
        return False

def update_data_for_all_users():
    """T√ºm kullanƒ±cƒ±larƒ±n watchlist'leri i√ßin veri g√ºncelle"""
    logger.info("üöÄ Background Worker: Veri g√ºncelleme d√∂ng√ºs√º ba≈üladƒ±...")
    
    with app.app_context():
        try:
            # Merkezi sistem API key kullan (fallback to ALPHA_VANTAGE_KEY)
            system_api_key = os.getenv('SYSTEM_ALPHA_VANTAGE_KEY') or os.getenv('ALPHA_VANTAGE_KEY')
            if not system_api_key:
                logger.error("‚ùå API anahtarƒ± bulunamadƒ±! (SYSTEM_ALPHA_VANTAGE_KEY veya ALPHA_VANTAGE_KEY)")
                return
                
            provider = AlphaVantageProvider(api_key=system_api_key, is_premium=True)
            logger.info(f"üîë Sistem API key kullanƒ±lƒ±yor: {system_api_key[:8]}...")

            # Veritabanƒ±ndan aktif varlƒ±klarƒ± √ßek (database-driven dynamic assets)
            available_assets = get_active_symbols_from_db()
            
            # T√ºm available sembol listesi (korelasyon i√ßin gerekli)
            all_available_symbols = set(available_assets['forex'] + 
                                       available_assets['stocks'] + 
                                       available_assets['crypto'])
            
            # Kullanƒ±cƒ± watchlist'lerinden sembolleri al
            all_watchlist_items = Watchlist.query.all()
            watchlist_symbols = {item.symbol for item in all_watchlist_items}
            
            # Kullanƒ±cƒ± watchlist'i + temel varlƒ±klar (minimum coverage i√ßin)
            # Eƒüer watchlist bo≈üsa, en azƒ±ndan major assets'ler analiz edilsin
            essential_symbols = {'AAPL', 'GOOGL', 'MSFT', 'NVDA', 'TSLA', 'EURUSD', 'BTCUSD', 'ETHUSD'}
            
            # Final unique symbols: watchlist + essential + intersect with available
            unique_symbols = (watchlist_symbols | essential_symbols) & all_available_symbols
            
            logger.info(f"üìä Available symbols: {len(all_available_symbols)}")
            logger.info(f"üìù Watchlist symbols: {len(watchlist_symbols)}")  
            logger.info(f"üîÑ Processing symbols: {len(unique_symbols)}")
            
            if len(unique_symbols) < 20:
                logger.warning(f"‚ö†Ô∏è Az sembol tespit edildi ({len(unique_symbols)}), t√ºm available symbols kullanƒ±lƒ±yor")
                unique_symbols = all_available_symbols

            successful_updates = 0
            
            # OPTIMIZASYON: Bulk asset info loading (N+1 query problemi √ß√∂z√ºm√º)
            asset_info_cache = {}
            with app.app_context():
                all_assets = Asset.query.filter(Asset.symbol.in_(unique_symbols), Asset.is_active == True).all()
                asset_info_cache = {asset.symbol: asset for asset in all_assets}
            
            for symbol in unique_symbols:
                try:
                    logger.info(f"üîÑ {symbol} verisi g√ºncelleniyor...")
                    
                    # AKILLI Fƒ∞LTRELEME: Asset type kontrol√º (Cache'den al)
                    asset_info = asset_info_cache.get(symbol)
                    
                    # Eƒüer varlƒ±k veritabanƒ±nda yok veya desteklenmeyen t√ºrde ise, atla
                    if not asset_info:
                        logger.warning(f"‚ö†Ô∏è {symbol} veritabanƒ±nda bulunamadƒ± veya pasif. Analiz atlanƒ±yor.")
                        continue
                    
                    # ETF'leri atla (News API desteklemiyor)
                    if asset_info.asset_type.lower() in ['etf', 'fund']:
                        logger.warning(f"‚ö†Ô∏è {symbol} bir ETF/Fund. News API desteklemiyor, analiz atlanƒ±yor.")
                        continue
                    
                    # TWTR gibi delisted stocks i√ßin ek kontrol
                    if symbol in ['TWTR', 'FB']:  # Bilinen delisted/renamed stocks
                        logger.warning(f"‚ö†Ô∏è {symbol} delisted/renamed stock. Analiz atlanƒ±yor.")
                        continue
                    
                    # Current price al
                    price = provider.get_current_price(symbol)
                    
                    # Asset type belirle (database-driven)
                    asset_type = get_asset_type(symbol, available_assets)
                    
                    # Framework ile analiz yap
                    framework = UniversalTradingBot(provider, asset_type)
                    analysis = framework.analyze_symbol(symbol)
                    
                    # Sentiment (sadece stocks i√ßin)
                    sentiment_score = None
                    if asset_type == AssetType.STOCKS:
                        try:
                            sentiment_data = provider.get_news_sentiment([symbol], limit=3)
                            sentiment_score = sentiment_data.get('overall_sentiment', 0)
                        except:
                            sentiment_score = 0

                    # üß† Akƒ±llƒ± skorlarƒ± hesapla
                    smart_scores = calculate_smart_scores(analysis, symbol)

                    # Database cache'e kaydet (Batch operation i√ßin prepare)
                    cached_data = CachedData.query.filter_by(symbol=symbol).first()
                    if cached_data:
                        # Mevcut kayƒ±t varsa g√ºncelle
                        cached_data.price = price
                        cached_data.signal = analysis.get('final_signal', 'hold') if 'error' not in analysis else 'error' 
                        cached_data.sentiment = sentiment_score
                        cached_data.confidence_score = smart_scores['confidence_score']
                        cached_data.technical_strength = smart_scores['technical_strength']
                        cached_data.volume_score = smart_scores['volume_score']
                        cached_data.momentum_score = smart_scores['momentum_score']
                        cached_data.risk_level = smart_scores['risk_level']
                        cached_data.last_updated = datetime.now()
                        cached_data.error_message = None
                    else:
                        # Yeni kayƒ±t olu≈ütur
                        cached_data = CachedData(
                            symbol=symbol,
                            price=price,
                            signal=analysis.get('final_signal', 'hold') if 'error' not in analysis else 'error',
                            sentiment=sentiment_score,
                            confidence_score=smart_scores['confidence_score'],
                            technical_strength=smart_scores['technical_strength'],
                            volume_score=smart_scores['volume_score'],
                            momentum_score=smart_scores['momentum_score'],
                            risk_level=smart_scores['risk_level'],
                            last_updated=datetime.now(),
                            error_message=None
                        )
                        db.session.add(cached_data)
                    
                    logger.info(f"‚úÖ {symbol}: ${price} | {analysis.get('final_signal', 'N/A')}")
                    successful_updates += 1
                    
                    # OPTIMIZASYON: Batch commit (configurable size)
                    if successful_updates % API_CONFIG['batch_commit_size'] == 0:
                        db.session.commit()
                        logger.debug(f"üìä Batch commit: {successful_updates} g√ºncelleme")
                    
                    # Rate limiting (configurable)
                    time.sleep(API_CONFIG['rate_limit_sleep'])
                    
                except Exception as e:
                    error_message = str(e)
                    logger.error(f"‚ùå {symbol} i√ßin veri √ßekilemedi: {error_message}")
                    
                    # AKILLI AUTO-DEACTIVATION: "Invalid API call" hatasƒ± varsa varlƒ±ƒüƒ± pasif yap
                    if "Invalid API call" in error_message:
                        try:
                            with app.app_context():
                                asset_to_deactivate = Asset.query.filter_by(symbol=symbol).first()
                                if asset_to_deactivate:
                                    asset_to_deactivate.is_active = False
                                    db.session.commit()
                                    logger.info(f"üîß {symbol} otomatik pasif yapƒ±ldƒ± (Invalid API call nedeniyle)")
                        except Exception as deactivate_error:
                            logger.error(f"‚ùå {symbol} pasif yapƒ±lamadƒ±: {deactivate_error}")
                    
                    # Hata durumunda database'e error kaydet
                    try:
                        cached_data = CachedData.query.filter_by(symbol=symbol).first()
                        if cached_data:
                            cached_data.error_message = error_message
                            cached_data.last_updated = datetime.now()
                            db.session.commit()
                    except Exception as db_error:
                        logger.error(f"‚ùå Database error for {symbol}: {db_error}")
                        db.session.rollback()

            # Final commit for remaining records
            if successful_updates > 0:
                db.session.commit()
                logger.debug("üìä Final commit completed")
            
            logger.info(f"‚úÖ Veri g√ºncelleme tamamlandƒ±: {successful_updates}/{len(unique_symbols)} ba≈üarƒ±lƒ±")
            
        except Exception as e:
            logger.error(f"‚ùå Genel g√ºncelleme hatasƒ±: {e}")
            db.session.rollback()  # Rollback on error

def main():
    """Ana worker d√∂ng√ºs√º"""
    logger.info("üöÄ Alpha Vantage Background Worker ba≈ülatƒ±ldƒ±")
    logger.info("üìä Her 1 dakikada veri g√ºncellenecek (hƒ±zlƒ± test modu)")
    logger.info(f"üìà Her {CORRELATION_CONFIG['update_interval_hours']} saatte korelasyon g√ºncellenecek")
    
    # Database tablolarƒ±nƒ± olu≈ütur (gerekirse)
    with app.app_context():
        db.create_all()
        logger.info("‚úÖ Database tables ready!")
    
    # Korelasyon hesaplama zamanlamasƒ±
    last_correlation_update = 0
    correlation_interval = CORRELATION_CONFIG['update_interval_hours'] * 3600  # Hours to seconds
    
    while True:
        try:
            # Korelasyon g√ºncellemesi kontrol√º (g√ºnde bir kez)
            if time.time() - last_correlation_update > correlation_interval:
                logger.info("üîÑ Korelasyon g√ºncelleme zamanƒ± geldi...")
                system_api_key = os.getenv('SYSTEM_ALPHA_VANTAGE_KEY') or os.getenv('ALPHA_VANTAGE_KEY')
                
                if system_api_key:
                    provider = AlphaVantageProvider(api_key=system_api_key, is_premium=True)
                    correlation_success = calculate_and_store_correlations(provider)
                    
                    if correlation_success:
                        last_correlation_update = time.time()
                        logger.info("‚úÖ Korelasyon g√ºncelleme tamamlandƒ±")
                    else:
                        logger.error("‚ùå Korelasyon g√ºncelleme ba≈üarƒ±sƒ±z - 1 saat sonra yeniden denenecek")
                        last_correlation_update = time.time() - correlation_interval + 3600  # Retry in 1 hour
                else:
                    logger.error("‚ùå API anahtarƒ± bulunamadƒ± - korelasyon g√ºncellenemiyor (SYSTEM_ALPHA_VANTAGE_KEY veya ALPHA_VANTAGE_KEY)")
            
            # Normal veri g√ºncelleme (configurable interval)
            update_data_for_all_users()
            sleep_minutes = API_CONFIG['worker_sleep_interval'] // 60
            logger.info(f"üïí Sonraki g√ºncelleme i√ßin {sleep_minutes} dakika bekleniyor...")
            time.sleep(API_CONFIG['worker_sleep_interval'])
            
        except KeyboardInterrupt:
            logger.info("üëã Background Worker durduruluyor...")
            break
        except Exception as e:
            logger.error(f"‚ùå Worker d√∂ng√ºs√º hatasƒ±: {e}")
            logger.info("üîÑ 30 saniye sonra yeniden denenecek...")
            time.sleep(30)

def generate_daily_briefing():
    """üéØ G√ºnl√ºk Piyasa Brifingi Olu≈ütur ve Database'e Kaydet"""
    with app.app_context():
        try:
            from datetime import date
            import json
            import random
            
            current_date = date.today()
            current_hour = datetime.now().hour
            
            logger.info(f"üìä G√ºnl√ºk briefing olu≈üturuluyor: {current_date} {current_hour}:00")
            
            # API key al
            system_api_key = os.getenv('SYSTEM_ALPHA_VANTAGE_KEY') or os.getenv('ALPHA_VANTAGE_KEY')
            if not system_api_key:
                logger.error("‚ùå API anahtarƒ± bulunamadƒ± - Briefing atlanƒ±yor")
                return
            
            # Provider sadece sentiment ve market movers i√ßin gerekli
            provider = AlphaVantageProvider(system_api_key, is_premium=True)
            
            # Mevcut briefing'i kontrol et
            existing_briefing = DailyBriefing.query.filter_by(
                briefing_date=current_date, 
                briefing_hour=current_hour
            ).first()
            
            if existing_briefing:
                logger.info(f"‚úÖ Bu saatte briefing zaten mevcut: {current_hour}:00")
                return existing_briefing.to_dict()
            
            # 1. Global Sentiment
            briefing_data = {
                'global_sentiment_score': 0.0,
                'global_sentiment_status': 'N√∂tr',
                'news_count': 0,
                'total_analyzed': 0,
                'buy_signals_count': 0,
                'sell_signals_count': 0,
                'top_opportunities': [],
                'recommendations': [],
                'market_movers_data': {}
            }
            
            try:
                sentiment_data = provider.get_news_sentiment(limit=50)
                briefing_data['global_sentiment_score'] = sentiment_data.get('overall_sentiment', 0)
                briefing_data['news_count'] = sentiment_data.get('news_count', 0)
                
                score = briefing_data['global_sentiment_score']
                briefing_data['global_sentiment_status'] = (
                    'Pozitif' if score > 0.1 else 
                    'Negatif' if score < -0.1 else 'N√∂tr'
                )
                logger.info(f"üìà Global sentiment: {briefing_data['global_sentiment_status']} ({score:.3f})")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Global sentiment hatasƒ±: {e}")
            
            # 2. CACHE'DEN Sƒ∞STEM TARAMASI - API √ßaƒürƒ±sƒ± YOK!
            try:
                from constants import AVAILABLE_ASSETS
                
                logger.info("üìä Cache'den sistem taramasƒ± ba≈ülƒ±yor...")
                
                # CachedData'dan t√ºm g√ºncel verileri al
                cached_data = CachedData.query.all()
                
                if not cached_data:
                    logger.warning("‚ö†Ô∏è Cache'de veri yok - Normal worker √ßalƒ±≈ümƒ±yor olabilir")
                    briefing_data['total_analyzed'] = 0
                else:
                    logger.info(f"üìà Cache'de {len(cached_data)} sembol verisi bulundu")
                    
                    briefing_data['total_analyzed'] = len(cached_data)
                    
                    # üß† AKILLI SIRALAMA: En iyi fƒ±rsatlarƒ± se√ß
                    buy_opportunities = []
                    sell_opportunities = []
                    
                    # BUY/SELL sinyallerini ayƒ±r ve skorla
                    for cached_item in cached_data:
                        try:
                            if cached_item.signal in ['buy', 'sell']:
                                # Asset tipini belirle
                                asset_type = 'Stock'
                                if cached_item.symbol in AVAILABLE_ASSETS['forex']:
                                    asset_type = 'Forex'
                                elif cached_item.symbol in AVAILABLE_ASSETS['crypto']:
                                    asset_type = 'Crypto'
                                
                                # Toplam kalite skoru hesapla (0-100)
                                quality_score = (
                                    cached_item.confidence_score * 0.4 +  # %40 confidence
                                    cached_item.technical_strength * 0.3 +  # %30 technical
                                    cached_item.momentum_score * 0.2 +     # %20 momentum
                                    cached_item.volume_score * 0.1         # %10 volume
                                )
                                
                                # Risk ayarlamasƒ±
                                if cached_item.risk_level == 'low':
                                    quality_score += 5.0  # D√º≈ü√ºk risk bonus
                                elif cached_item.risk_level == 'high':
                                    quality_score -= 5.0  # Y√ºksek risk cezasƒ±
                                
                                opportunity = {
                                    'symbol': cached_item.symbol,
                                    'signal': cached_item.signal.upper(),
                                    'price': cached_item.price,
                                    'asset_type': asset_type,
                                    'confidence_score': cached_item.confidence_score,
                                    'technical_strength': cached_item.technical_strength,
                                    'quality_score': round(quality_score, 2),
                                    'risk_level': cached_item.risk_level,
                                    'recommendation_reason': _generate_recommendation_reason(cached_item)
                                }
                                
                                if cached_item.signal == 'buy':
                                    buy_opportunities.append(opportunity)
                                    briefing_data['buy_signals_count'] += 1
                                else:
                                    sell_opportunities.append(opportunity)
                                    briefing_data['sell_signals_count'] += 1
                                    
                        except Exception as e:
                            logger.warning(f"Cache okuma hatasƒ± {cached_item.symbol}: {e}")
                            continue
                    
                    # En iyi fƒ±rsatlarƒ± se√ß (kalite skoruna g√∂re sƒ±rala)
                    buy_opportunities.sort(key=lambda x: x['quality_score'], reverse=True)
                    sell_opportunities.sort(key=lambda x: x['quality_score'], reverse=True)
                    
                    # En iyi 8 BUY + 7 SELL al (toplam 15)
                    best_buys = buy_opportunities[:8]
                    best_sells = sell_opportunities[:7]
                    
                    # Briefing data'ya ekle
                    briefing_data['top_opportunities'] = best_buys + best_sells
                    
                    logger.info(f"üéØ En iyi fƒ±rsatlar se√ßildi: {len(best_buys)} BUY, {len(best_sells)} SELL")
                    
                    logger.info(f"‚úÖ Cache'den {briefing_data['total_analyzed']} sembol okundu, {len(briefing_data['top_opportunities'])} fƒ±rsat bulundu")
                
            except Exception as e:
                logger.error(f"‚ùå Cache okuma hatasƒ±: {e}")
            
            # 3. Market Movers (Alpha Intelligence)
            try:
                from alpha_intelligence_provider import AlphaIntelligenceProvider
                intelligence_provider = AlphaIntelligenceProvider(system_api_key, is_premium=True)
                market_movers = intelligence_provider.get_top_gainers_losers()
                briefing_data['market_movers_data'] = market_movers
                logger.info("üìà Market movers verisi alƒ±ndƒ±")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Market movers hatasƒ±: {e}")
                briefing_data['market_movers_data'] = {}
            
            # 4. Akƒ±llƒ± √ñneriler Olu≈ütur
            recommendations = []
            sentiment_score = briefing_data['global_sentiment_score']
            buy_count = briefing_data['buy_signals_count']
            sell_count = briefing_data['sell_signals_count']
            total_opportunities = len(briefing_data['top_opportunities'])
            
            # Ana strateji
            if sentiment_score > 0.1 and buy_count > sell_count:
                recommendations.append("üü¢ Pozitif piyasa sentiment - Alƒ±m fƒ±rsatlarƒ±nƒ± deƒüerlendirin")
            elif sentiment_score < -0.1 and sell_count > buy_count:
                recommendations.append("üî¥ Negatif piyasa sentiment - Risk y√∂netimi yapƒ±n")
            else:
                recommendations.append("üü° Karƒ±≈üƒ±k sinyaller - Temkinli yakla≈üƒ±n")
            
            # Fƒ±rsat analizi
            if total_opportunities == 0:
                recommendations.append("‚è∏Ô∏è Net sinyal yok - Bekleyici pozisyon alƒ±n")
            elif total_opportunities <= 3:
                recommendations.append("üìä Az sayƒ±da fƒ±rsat - Se√ßici davranƒ±n")
            elif total_opportunities >= 8:
                recommendations.append("üéØ √áok sayƒ±da fƒ±rsat - Portf√∂y √ße≈üitliliƒüi yapƒ±n")
            
            # Asset daƒüƒ±lƒ±mƒ±
            asset_counts = {}
            for opp in briefing_data['top_opportunities']:
                asset_type = opp.get('asset_type', 'Stock')
                asset_counts[asset_type] = asset_counts.get(asset_type, 0) + 1
            
            if asset_counts.get('Stock', 0) > asset_counts.get('Forex', 0) + asset_counts.get('Crypto', 0):
                recommendations.append("üìà Hisse senetlerinde daha fazla aktivite")
            elif asset_counts.get('Forex', 0) > 0:
                recommendations.append("üí± Forex piyasasƒ±nda hareket var")
            elif asset_counts.get('Crypto', 0) > 0:
                recommendations.append("‚Çø Kripto piyasasƒ±nda fƒ±rsatlar mevcut")
            
            recommendations.append(f"üîç {briefing_data['total_analyzed']} sembol analiz edildi (Sistem: 73 enstr√ºman)")
            
            briefing_data['recommendations'] = recommendations
            
            # 5. Database'e Kaydet
            new_briefing = DailyBriefing(
                briefing_date=current_date,
                briefing_hour=current_hour,
                global_sentiment_score=briefing_data['global_sentiment_score'],
                global_sentiment_status=briefing_data['global_sentiment_status'],
                news_count=briefing_data['news_count'],
                total_analyzed=briefing_data['total_analyzed'],
                buy_signals_count=briefing_data['buy_signals_count'],
                sell_signals_count=briefing_data['sell_signals_count'],
                top_opportunities=json.dumps(briefing_data['top_opportunities']),
                recommendations=json.dumps(briefing_data['recommendations']),
                market_movers_data=json.dumps(briefing_data['market_movers_data'])
            )
            
            db.session.add(new_briefing)
            db.session.commit()
            
            logger.info(f"‚úÖ G√ºnl√ºk briefing kaydedildi: {len(briefing_data['top_opportunities'])} fƒ±rsat, {len(briefing_data['recommendations'])} √∂neri")
            
            return new_briefing.to_dict()
            
        except Exception as e:
            logger.error(f"‚ùå G√ºnl√ºk briefing hatasƒ±: {e}")
            db.session.rollback()
            return None

def _generate_recommendation_reason(cached_item):
    """üéØ √ñneri nedeni olu≈ütur"""
    try:
        reasons = []
        
        # Confidence-based reasons
        if cached_item.confidence_score >= 85:
            reasons.append("√áok y√ºksek g√ºven skoru")
        elif cached_item.confidence_score >= 75:
            reasons.append("Y√ºksek g√ºven skoru")
        
        # Technical strength
        if cached_item.technical_strength >= 80:
            reasons.append("G√º√ßl√º teknik sinyaller")
        elif cached_item.technical_strength >= 70:
            reasons.append("Olumlu teknik g√∂r√ºn√ºm")
        
        # Risk level
        if cached_item.risk_level == 'low':
            reasons.append("D√º≈ü√ºk risk profili")
        
        # Momentum
        if cached_item.momentum_score >= 70:
            reasons.append("G√º√ßl√º momentum")
        
        # Default reason
        if not reasons:
            reasons.append("Sistem analizi √∂nerisi")
        
        return ", ".join(reasons[:2])  # En fazla 2 neden
        
    except:
        return "Sistem analizi √∂nerisi"

def enhanced_worker_main():
    """üöÄ Geli≈ümi≈ü Worker - Saatlik briefing ile"""
    logger.info("üöÄ Geli≈ümi≈ü Background Worker ba≈ülatƒ±lƒ±yor...")
    logger.info("üìä √ñzellikler: Veri g√ºncelleme + Saatlik briefing")
    
    last_briefing_hour = -1  # ƒ∞lk √ßalƒ±≈ümada briefing yap
    
    while True:
        try:
            current_hour = datetime.now().hour
            
            # Saatlik briefing kontrol√º
            if current_hour != last_briefing_hour:
                logger.info(f"üéØ Saatlik briefing zamanƒ±: {current_hour}:00")
                generate_daily_briefing()
                last_briefing_hour = current_hour
            
            # Normal veri g√ºncelleme
            logger.info("üîÑ Veri g√ºncelleme ba≈ülƒ±yor...")
            update_data_for_all_users()
            
            # Bekleme
            sleep_minutes = API_CONFIG['worker_sleep_interval'] // 60
            logger.info(f"üïí Sonraki g√ºncelleme i√ßin {sleep_minutes} dakika bekleniyor...")
            time.sleep(API_CONFIG['worker_sleep_interval'])
            
        except KeyboardInterrupt:
            logger.info("üëã Geli≈ümi≈ü Background Worker durduruluyor...")
            break
        except Exception as e:
            logger.error(f"‚ùå Geli≈ümi≈ü worker d√∂ng√ºs√º hatasƒ±: {e}")
            logger.info("üîÑ 30 saniye sonra yeniden denenecek...")
            time.sleep(30)

if __name__ == '__main__':
    # Geli≈ümi≈ü worker'ƒ± ba≈ülat
    enhanced_worker_main() 