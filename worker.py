#!/usr/bin/env python3
"""
ğŸ”„ Alpha Vantage Trading Framework - Background Worker
Arka planda sÃ¼rekli Ã§alÄ±ÅŸarak veri gÃ¼ncelleme sistemi
"""

import time
import os
import logging
from datetime import datetime

# Flask app ve modellerini import et
from web_app import app, db, User, Watchlist, CachedData, CorrelationCache, Asset
from alphavantage_provider import AlphaVantageProvider
from universal_trading_framework import UniversalTradingBot, AssetType

# Import configurations
from constants import CORRELATION_CONFIG, API_CONFIG

# Additional imports for correlation calculation
import pandas as pd
from sqlalchemy import text

# Loglama kurulumu
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def get_asset_type(symbol, available_assets):
    """Sembol iÃ§in doÄŸru asset type'Ä± bul"""
    for asset_type, symbols in available_assets.items():
        if symbol in symbols:
            if asset_type == 'forex':
                return AssetType.FOREX
            elif asset_type == 'stocks':
                return AssetType.STOCKS
            elif asset_type == 'crypto':
                return AssetType.CRYPTO
    return AssetType.STOCKS  # Default

def get_active_symbols_from_db():
    """VeritabanÄ±ndan aktif olan tÃ¼m varlÄ±k sembollerini Ã§eker"""
    with app.app_context():
        try:
            # Asset tablosundan aktif varlÄ±klarÄ± Ã§ek (web_app.py ile tutarlÄ± naming)
            forex_assets = [a.symbol for a in Asset.query.filter_by(asset_type='forex', is_active=True).all()]
            stock_assets = [a.symbol for a in Asset.query.filter_by(asset_type='stocks', is_active=True).all()]  
            crypto_assets = [a.symbol for a in Asset.query.filter_by(asset_type='crypto', is_active=True).all()]
            
            logger.info(f"ğŸ“Š Database'den Ã§ekilen varlÄ±klar:")
            logger.info(f"   Forex: {len(forex_assets)} varlÄ±k")
            logger.info(f"   Stocks: {len(stock_assets)} varlÄ±k")  
            logger.info(f"   Crypto: {len(crypto_assets)} varlÄ±k")
            
            # EÄŸer database boÅŸsa, fallback constants kullan
            total_assets = len(forex_assets) + len(stock_assets) + len(crypto_assets)
            
            if total_assets == 0:
                logger.warning("âš ï¸ Database'de varlÄ±k bulunamadÄ±, fallback constants kullanÄ±lÄ±yor")
                # Fallback to constants if database is empty
                from constants import AVAILABLE_ASSETS
                return AVAILABLE_ASSETS
            
            return {
                'forex': forex_assets,
                'stocks': stock_assets,
                'crypto': crypto_assets
            }
        except Exception as e:
            logger.error(f"âŒ Database varlÄ±k okuma hatasÄ±: {e}")
            logger.warning("âš ï¸ Fallback constants kullanÄ±lÄ±yor")
            # Fallback to constants on error
            from constants import AVAILABLE_ASSETS
            return AVAILABLE_ASSETS

def calculate_and_store_correlations(provider):
    """TÃ¼m varlÄ±klar iÃ§in korelasyon matrisini hesaplar ve veritabanÄ±na kaydeder"""
    logger.info("ğŸ“ˆ Dinamik korelasyon hesaplamasÄ± baÅŸlÄ±yor...")
    
    # TÃ¼m sembolleri database'den al
    available_assets = get_active_symbols_from_db()
    all_symbols = (available_assets['forex'] + 
                   available_assets['stocks'] + 
                   available_assets['crypto'])
    
    price_data = {}
    
    logger.info(f"ğŸ“Š Tarihsel veri Ã§ekiliyor ({len(all_symbols)} varlÄ±k)...")
    
    for symbol in all_symbols:
        try:
            # 90 gÃ¼nlÃ¼k veri al (daha stabil korelasyon iÃ§in)
            days_back = CORRELATION_CONFIG['historical_days']
            # 15dk periyotlarla gÃ¼nlÃ¼k data: 96 periyot/gÃ¼n * 90 gÃ¼n = 8640 periyot
            data_points = 96 * days_back
            
            df = provider.get_historical_data(symbol, 
                                            CORRELATION_CONFIG['timeframe'], 
                                            data_points)
            
            if not df.empty and len(df) >= CORRELATION_CONFIG['min_data_points']:
                # Close fiyatlarÄ± al
                price_data[symbol] = df['Close'].ffill(limit=10).dropna()
                logger.info(f"âœ… {symbol}: {len(price_data[symbol])} veri noktasÄ±")
            else:
                logger.warning(f"âš ï¸ {symbol}: Yetersiz veri ({len(df) if not df.empty else 0} nokta)")
            
            # Rate limiting
            time.sleep(1.5)
            
        except Exception as e:
            logger.warning(f"âŒ {symbol} korelasyon verisi alÄ±namadÄ±: {e}")

    if len(price_data) < 10:
        logger.error("âŒ Korelasyon iÃ§in yeterli veri toplanamadÄ±.")
        return False

    try:
        # YÃ¼zdesel deÄŸiÅŸime gÃ¶re korelasyon hesapla (daha stabil)
        full_df = pd.DataFrame(price_data).pct_change(fill_method=None).dropna()
        correlation_matrix = full_df.corr()
        
        logger.info("âœ… Korelasyon matrisi hesaplandÄ±. VeritabanÄ±na kaydediliyor...")
        
        # Flask app context iÃ§inde database iÅŸlemleri
        with app.app_context():
            # VeritabenÄ±na kaydet
            valid_correlations = 0
            
            # Ã–nceki verileri temizle
            CorrelationCache.query.delete()
            
            # Yeni verileri ekle
            for symbol_1 in correlation_matrix.columns:
                for symbol_2 in correlation_matrix.columns:
                    if symbol_1 >= symbol_2:  # TekrarlÄ± Ã§iftleri Ã¶nle
                        continue
                    
                    corr_value = correlation_matrix.loc[symbol_1, symbol_2]
                    
                    # NaN olmayan ve anlamlÄ± korelasyonlarÄ± kaydet
                    if pd.notna(corr_value) and abs(corr_value) >= CORRELATION_CONFIG['correlation_threshold']:
                        new_corr = CorrelationCache(
                            symbol_1=symbol_1,
                            symbol_2=symbol_2,
                            correlation_value=float(corr_value)
                        )
                        db.session.add(new_corr)
                        valid_correlations += 1
            
            db.session.commit()
            logger.info(f"âœ… {valid_correlations} anlamlÄ± korelasyon veritabanÄ±na kaydedildi")
            
            # Ã–rnek korelasyonlarÄ± logla
            sample_corrs = CorrelationCache.query.order_by(CorrelationCache.correlation_value.desc()).limit(5).all()
            for corr in sample_corrs:
                logger.info(f"ğŸ“Š En yÃ¼ksek korelasyon: {corr.symbol_1} â†” {corr.symbol_2}: {corr.correlation_value:.3f}")
                
        return True
        
    except Exception as e:
        logger.error(f"âŒ Korelasyon hesaplama/kaydetme hatasÄ±: {e}")
        with app.app_context():
            db.session.rollback()
        return False

def update_data_for_all_users():
    """TÃ¼m kullanÄ±cÄ±larÄ±n watchlist'leri iÃ§in veri gÃ¼ncelle"""
    logger.info("ğŸš€ Background Worker: Veri gÃ¼ncelleme dÃ¶ngÃ¼sÃ¼ baÅŸladÄ±...")
    
    with app.app_context():
        try:
            # TÃ¼m kullanÄ±cÄ±larÄ± kontrol et (watchlist iÃ§in gerekli)
            users = User.query.all()
            if not users:
                logger.warning("âŒ HiÃ§ kullanÄ±cÄ± bulunamadÄ±. Bekleniyor...")
                return

            # Merkezi sistem API key kullan
            system_api_key = os.getenv('SYSTEM_ALPHA_VANTAGE_KEY')
            if not system_api_key:
                logger.error("âŒ SYSTEM_ALPHA_VANTAGE_KEY environment variable bulunamadÄ±!")
                return
                
            provider = AlphaVantageProvider(api_key=system_api_key, is_premium=True)
            logger.info(f"ğŸ”‘ Sistem API key kullanÄ±lÄ±yor: {system_api_key[:8]}...")

            # VeritabanÄ±ndan aktif varlÄ±klarÄ± Ã§ek (database-driven dynamic assets)
            available_assets = get_active_symbols_from_db()
            
            # TÃ¼m available sembol listesi (korelasyon iÃ§in gerekli)
            all_available_symbols = set(available_assets['forex'] + 
                                       available_assets['stocks'] + 
                                       available_assets['crypto'])
            
            # KullanÄ±cÄ± watchlist'lerinden sembolleri al
            all_watchlist_items = Watchlist.query.all()
            watchlist_symbols = {item.symbol for item in all_watchlist_items}
            
            # KullanÄ±cÄ± watchlist'i + temel varlÄ±klar (minimum coverage iÃ§in)
            # EÄŸer watchlist boÅŸsa, en azÄ±ndan major assets'ler analiz edilsin
            essential_symbols = {'AAPL', 'GOOGL', 'MSFT', 'NVDA', 'TSLA', 'EURUSD', 'BTCUSD', 'ETHUSD'}
            
            # Final unique symbols: watchlist + essential + intersect with available
            unique_symbols = (watchlist_symbols | essential_symbols) & all_available_symbols
            
            logger.info(f"ğŸ“Š Available symbols: {len(all_available_symbols)}")
            logger.info(f"ğŸ“ Watchlist symbols: {len(watchlist_symbols)}")  
            logger.info(f"ğŸ”„ Processing symbols: {len(unique_symbols)}")
            
            if len(unique_symbols) < 20:
                logger.warning(f"âš ï¸ Az sembol tespit edildi ({len(unique_symbols)}), tÃ¼m available symbols kullanÄ±lÄ±yor")
                unique_symbols = all_available_symbols

            successful_updates = 0
            
            # OPTIMIZASYON: Bulk asset info loading (N+1 query problemi Ã§Ã¶zÃ¼mÃ¼)
            asset_info_cache = {}
            with app.app_context():
                all_assets = Asset.query.filter(Asset.symbol.in_(unique_symbols), Asset.is_active == True).all()
                asset_info_cache = {asset.symbol: asset for asset in all_assets}
            
            for symbol in unique_symbols:
                try:
                    logger.info(f"ğŸ”„ {symbol} verisi gÃ¼ncelleniyor...")
                    
                    # AKILLI FÄ°LTRELEME: Asset type kontrolÃ¼ (Cache'den al)
                    asset_info = asset_info_cache.get(symbol)
                    
                    # EÄŸer varlÄ±k veritabanÄ±nda yok veya desteklenmeyen tÃ¼rde ise, atla
                    if not asset_info:
                        logger.warning(f"âš ï¸ {symbol} veritabanÄ±nda bulunamadÄ± veya pasif. Analiz atlanÄ±yor.")
                        continue
                    
                    # ETF'leri atla (News API desteklemiyor)
                    if asset_info.asset_type.lower() in ['etf', 'fund']:
                        logger.warning(f"âš ï¸ {symbol} bir ETF/Fund. News API desteklemiyor, analiz atlanÄ±yor.")
                        continue
                    
                    # TWTR gibi delisted stocks iÃ§in ek kontrol
                    if symbol in ['TWTR', 'FB']:  # Bilinen delisted/renamed stocks
                        logger.warning(f"âš ï¸ {symbol} delisted/renamed stock. Analiz atlanÄ±yor.")
                        continue
                    
                    # Current price al
                    price = provider.get_current_price(symbol)
                    
                    # Asset type belirle (database-driven)
                    asset_type = get_asset_type(symbol, available_assets)
                    
                    # Framework ile analiz yap
                    framework = UniversalTradingBot(provider, asset_type)
                    analysis = framework.analyze_symbol(symbol)
                    
                    # Sentiment (sadece stocks iÃ§in)
                    sentiment_score = None
                    if asset_type == AssetType.STOCKS:
                        try:
                            sentiment_data = provider.get_news_sentiment([symbol], limit=3)
                            sentiment_score = sentiment_data.get('overall_sentiment', 0)
                        except:
                            sentiment_score = 0

                    # Database cache'e kaydet (Batch operation iÃ§in prepare)
                    cached_data = CachedData.query.filter_by(symbol=symbol).first()
                    if cached_data:
                        # Mevcut kayÄ±t varsa gÃ¼ncelle
                        cached_data.price = price
                        cached_data.signal = analysis.get('final_signal', 'hold') if 'error' not in analysis else 'error' 
                        cached_data.sentiment = sentiment_score
                        cached_data.last_updated = datetime.now()
                        cached_data.error_message = None
                    else:
                        # Yeni kayÄ±t oluÅŸtur
                        cached_data = CachedData(
                            symbol=symbol,
                            price=price,
                            signal=analysis.get('final_signal', 'hold') if 'error' not in analysis else 'error',
                            sentiment=sentiment_score,
                            last_updated=datetime.now(),
                            error_message=None
                        )
                        db.session.add(cached_data)
                    
                    logger.info(f"âœ… {symbol}: ${price} | {analysis.get('final_signal', 'N/A')}")
                    successful_updates += 1
                    
                    # OPTIMIZASYON: Batch commit (configurable size)
                    if successful_updates % API_CONFIG['batch_commit_size'] == 0:
                        db.session.commit()
                        logger.debug(f"ğŸ“Š Batch commit: {successful_updates} gÃ¼ncelleme")
                    
                    # Rate limiting (configurable)
                    time.sleep(API_CONFIG['rate_limit_sleep'])
                    
                except Exception as e:
                    error_message = str(e)
                    logger.error(f"âŒ {symbol} iÃ§in veri Ã§ekilemedi: {error_message}")
                    
                    # AKILLI AUTO-DEACTIVATION: "Invalid API call" hatasÄ± varsa varlÄ±ÄŸÄ± pasif yap
                    if "Invalid API call" in error_message:
                        try:
                            with app.app_context():
                                asset_to_deactivate = Asset.query.filter_by(symbol=symbol).first()
                                if asset_to_deactivate:
                                    asset_to_deactivate.is_active = False
                                    db.session.commit()
                                    logger.info(f"ğŸ”§ {symbol} otomatik pasif yapÄ±ldÄ± (Invalid API call nedeniyle)")
                        except Exception as deactivate_error:
                            logger.error(f"âŒ {symbol} pasif yapÄ±lamadÄ±: {deactivate_error}")
                    
                    # Hata durumunda database'e error kaydet
                    try:
                        cached_data = CachedData.query.filter_by(symbol=symbol).first()
                        if cached_data:
                            cached_data.error_message = error_message
                            cached_data.last_updated = datetime.now()
                            db.session.commit()
                    except Exception as db_error:
                        logger.error(f"âŒ Database error for {symbol}: {db_error}")
                        db.session.rollback()

            # Final commit for remaining records
            if successful_updates > 0:
                db.session.commit()
                logger.debug("ğŸ“Š Final commit completed")
            
            logger.info(f"âœ… Veri gÃ¼ncelleme tamamlandÄ±: {successful_updates}/{len(unique_symbols)} baÅŸarÄ±lÄ±")
            
        except Exception as e:
            logger.error(f"âŒ Genel gÃ¼ncelleme hatasÄ±: {e}")
            db.session.rollback()  # Rollback on error

def main():
    """Ana worker dÃ¶ngÃ¼sÃ¼"""
    logger.info("ğŸš€ Alpha Vantage Background Worker baÅŸlatÄ±ldÄ±")
    logger.info("ğŸ“Š Her 5 dakikada veri gÃ¼ncellenecek")
    logger.info(f"ğŸ“ˆ Her {CORRELATION_CONFIG['update_interval_hours']} saatte korelasyon gÃ¼ncellenecek")
    
    # Database tablolarÄ±nÄ± oluÅŸtur (gerekirse)
    with app.app_context():
        db.create_all()
        logger.info("âœ… Database tables ready!")
    
    # Korelasyon hesaplama zamanlamasÄ±
    last_correlation_update = 0
    correlation_interval = CORRELATION_CONFIG['update_interval_hours'] * 3600  # Hours to seconds
    
    while True:
        try:
            # Korelasyon gÃ¼ncellemesi kontrolÃ¼ (gÃ¼nde bir kez)
            if time.time() - last_correlation_update > correlation_interval:
                logger.info("ğŸ”„ Korelasyon gÃ¼ncelleme zamanÄ± geldi...")
                system_api_key = os.getenv('SYSTEM_ALPHA_VANTAGE_KEY')
                
                if system_api_key:
                    provider = AlphaVantageProvider(api_key=system_api_key, is_premium=True)
                    correlation_success = calculate_and_store_correlations(provider)
                    
                    if correlation_success:
                        last_correlation_update = time.time()
                        logger.info("âœ… Korelasyon gÃ¼ncelleme tamamlandÄ±")
                    else:
                        logger.error("âŒ Korelasyon gÃ¼ncelleme baÅŸarÄ±sÄ±z - 1 saat sonra yeniden denenecek")
                        last_correlation_update = time.time() - correlation_interval + 3600  # Retry in 1 hour
                else:
                    logger.error("âŒ SYSTEM_ALPHA_VANTAGE_KEY bulunamadÄ± - korelasyon gÃ¼ncellenemiyor")
            
            # Normal veri gÃ¼ncelleme (configurable interval)
            update_data_for_all_users()
            sleep_minutes = API_CONFIG['worker_sleep_interval'] // 60
            logger.info(f"ğŸ•’ Sonraki gÃ¼ncelleme iÃ§in {sleep_minutes} dakika bekleniyor...")
            time.sleep(API_CONFIG['worker_sleep_interval'])
            
        except KeyboardInterrupt:
            logger.info("ğŸ‘‹ Background Worker durduruluyor...")
            break
        except Exception as e:
            logger.error(f"âŒ Worker dÃ¶ngÃ¼sÃ¼ hatasÄ±: {e}")
            logger.info("ğŸ”„ 30 saniye sonra yeniden denenecek...")
            time.sleep(30)

if __name__ == '__main__':
    main() 